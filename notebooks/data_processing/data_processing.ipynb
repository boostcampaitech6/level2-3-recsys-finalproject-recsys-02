{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의존성 파일 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-bigquery\n",
    "# !pip install gspread oauth2client\n",
    "# !pip install db-dtypes\n",
    "# !pip install pandas-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from crwlnt.notiAPI.product import NotiServerRequest\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구글 클라우드 연동 및 BigQuery에서 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_FILE = \"./config/level3-416207-893f91c9529e.json\"  # 키 json 파일\n",
    "\n",
    "# Credentials 객체 생성\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
    "\n",
    "# 빅쿼리 클라이언트 객체 생성\n",
    "project_id = \"level3-416207\"\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "\n",
    "# 쿼리 실행\n",
    "# 빅쿼리 디렉토리는 <프로젝트ID>.<데이터셋ID>.<테이블ID> 순으로 저장되어있음 ex) level3-416207.l3_30.l3_30\n",
    "QUERY = (\n",
    "    '''\n",
    "    SELECT hashed_ip, local_time, request_url_endpoint, uri_first\n",
    "    FROM `level3-416207.log_129.revised_log_129`\n",
    "    WHERE local_time >= TIMESTAMP '2024-01-29 00:00:00 UTC'\n",
    "    ''')\n",
    "\n",
    "\n",
    "# API request\n",
    "df = client.query(QUERY).to_dataframe()\n",
    "df = df.sort_values('local_time')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /spec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spec = df[df['uri_first']=='spec']\n",
    "df_spec['products'] = df_spec['request_url_endpoint'].map(lambda x: x[6:])\n",
    "df_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_spec = df_spec.loc[:, ['hashed_ip', 'local_time', 'products', 'uri_first']]\n",
    "df_new_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_spec.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /redirect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redirect = df[df['uri_first']=='redirect']\n",
    "df_redirect['products'] = df_redirect['request_url_endpoint'].map(lambda x: x[10:])\n",
    "df_redirect = df_redirect[df_redirect['products'].str.startswith('?p=')]\n",
    "df_redirect['products'] = df_redirect['products'].map(lambda x: x.split('&')[0].split('=')[1] + '-' + x.split('&')[1].split('=')[1] + '-' +x.split('&')[2].split('=')[1])\n",
    "df_redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_redirect = df_redirect.loc[:,['hashed_ip', 'local_time', 'products', 'uri_first']]\n",
    "df_new_redirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_redirect.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = df[df['uri_first'].str.startswith('?p=', na=False)]\n",
    "\n",
    "df_re['products'] = None\n",
    "for i in list(df_re.index):\n",
    "    try:\n",
    "        df_re.loc[i,'products'] = df_re.loc[i, 'uri_first'].split('&')[0].split('=')[1] + '-' + df_re.loc[i, 'uri_first'].split('&')[1].split('=')[1] + '-' + df_re.loc[i, 'uri_first'].split('&')[2].split('=')[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_re = df_re[df_re['products'].isna()==False].loc[:,['hashed_ip', 'local_time', 'products']]\n",
    "df_new_re['uri_first'] = 'redirect'\n",
    "df_new_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_re.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = pd.concat([df_new_re, df_new_redirect, df_new_spec], axis=0, ignore_index=True)\n",
    "\n",
    "interaction['products'] = interaction['products'].astype(str)\n",
    "\n",
    "for i in tqdm(list(interaction.index)):\n",
    "    if '/' in interaction.loc[i,'products']:\n",
    "        interaction.loc[i, 'products'] = interaction.loc[i, 'products'].split('/')[0]\n",
    "\n",
    "interaction = interaction[interaction['products']!='']\n",
    "interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## product_id/piv 형태만 남기고 검색되는 product의 interaction만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_product_id = interaction[interaction['products'].apply(lambda x: len(str(x)) == 64)]\n",
    "interaction_piv = interaction[interaction['products'].str.contains('-')]\n",
    "\n",
    "product_id_list = list(set(interaction_product_id['products'].values))\n",
    "product_piv_list = list(set(interaction_piv['products'].values))\n",
    "\n",
    "\n",
    "print(len(product_id_list))\n",
    "print(len(product_piv_list))\n",
    "print(len(product_id_list) + len(product_piv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 개수로 product_id/piv 리스트 자르기\n",
    "def chunk_array(array, chunk_size):\n",
    "    return [array[i:i+chunk_size] for i in range(0, len(array), chunk_size)]\n",
    "\n",
    "\n",
    "# 원하는 개수만큼 request 보내기\n",
    "def send_array_in_chunks(array, chunk_size, type):\n",
    "    chunks = chunk_array(array, chunk_size)\n",
    "    product_df = pd.DataFrame(columns=['id', 'piv', 'title'])\n",
    "    for chunk in chunks:\n",
    "        if type == 'ids':\n",
    "            res = NotiServerRequest.bulk_product_info(ids=chunk)\n",
    "        else:\n",
    "            res = NotiServerRequest.bulk_product_info(pivs=chunk)\n",
    "\n",
    "        result = res.json()['data']['products']\n",
    "        for j in range(len(result)):\n",
    "            try:\n",
    "                product_df.loc[len(product_df)] = [result[j]['id'], result[j]['piv'], result[j]['title']]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        print(len(product_df))\n",
    "        time.sleep(11)\n",
    "    return product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n개씩 묶어서 보내기, 남은 원소들 보내기\n",
    "chunk_size = 5000\n",
    "\n",
    "id_list_df = send_array_in_chunks(product_id_list, chunk_size, 'ids')\n",
    "piv_list_df = send_array_in_chunks(product_piv_list, chunk_size, 'pivs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색해도 안 나오는 product_id, piv 지우기\n",
    "# product_~~_list = 로그에 등장한 product_id/piv 중복 없이 전부 다 있는 list\n",
    "# ~~_list_df = api로 검색했을 때 검색이 된 상품을 모아놓은 df\n",
    "# set(product_id_list) - set(id_list_df['id'].values) => 차집합 이용해서 전체로그에는 있지만 검색이 안 된 product_id 찾기\n",
    "\n",
    "id_error_dict = {id_error:None for id_error in list(set(product_id_list) - set(id_list_df['id'].values))}\n",
    "piv_error_dict = {piv_error:None for piv_error in list(set(product_piv_list) - set(piv_list_df['piv'].values))}\n",
    "\n",
    "interaction_product_id['products'] = interaction_product_id['products'].map(lambda x: id_error_dict[x] if x in list(id_error_dict.keys()) else x)\n",
    "interaction_piv['products'] = interaction_piv['products'].map(lambda x: piv_error_dict[x] if x in list(piv_error_dict.keys()) else x)\n",
    "\n",
    "interaction_product_id = interaction_product_id[interaction_product_id['products'].notnull()]\n",
    "interaction_piv = interaction_piv[interaction_piv['products'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파생) item.csv 파일 저장 및 불러오기\n",
    "- id, piv, title 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = pd.concat([id_list_df, piv_list_df], axis=0, ignore_index=True)\n",
    "product_data['title'] = product_data['title'].map(lambda x: x.replace(\"'\",'').replace(',','').replace('(', ' ').replace(')', ' '))\n",
    "product_data['title'] = product_data['title'].map(lambda x: x.lower())\n",
    "product_data['title'] = product_data['title'].map(lambda x: x.split(' '))\n",
    "product_data['title'] = product_data['title'].map(lambda x: ' '.join(x).split())\n",
    "product_data['title'] = product_data['title'].map(lambda x: ' '.join(x))\n",
    "product_data = product_data.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "product_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.to_csv('./item.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interaction 파일 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# piv가 필요하다면 실행하지 않아야 할 셀!\n",
    "# piv:id dict 만들기\n",
    "piv_id_dict = { product_data.loc[i, 'piv']:product_data.loc[i, 'id'] for i in tqdm(range(len(product_data)))}\n",
    "\n",
    "# piv를 product_id로 바꾸기\n",
    "interaction_piv['products'] = interaction_piv['products'].map(piv_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction dataframe 만들기\n",
    "interaction_data = pd.concat([interaction_piv, interaction_product_id], axis=0, ignore_index=True)\n",
    "interaction_data['uri_first'] = interaction_data['uri_first'].map(lambda x: 1 if x=='spec' else 0)\n",
    "interaction_data = interaction_data.sort_values('local_time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data.to_csv('./crwlnt/data_csv/interaction/inter_240129.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_idx = {ip:idx for idx, ip in enumerate(interaction_data['hashed_ip'].unique())}\n",
    "idx_to_user = {idx:ip for idx, ip in enumerate(interaction_data['hashed_ip'].unique())}\n",
    "item_to_idx = {pid:idx for idx, pid in enumerate(product_data['id'].unique())}\n",
    "idx_to_item = {idx:pid for idx, pid in enumerate(product_data['id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_to_idx.pickle','wb') as fw:\n",
    "    pickle.dump(user_to_idx, fw)\n",
    "\n",
    "with open('idx_to_user.pickle','wb') as fw:\n",
    "    pickle.dump(idx_to_user, fw)\n",
    "\n",
    "with open('item_to_idx.pickle','wb') as fw:\n",
    "    pickle.dump(item_to_idx, fw)\n",
    "\n",
    "with open('idx_to_item.pickle','wb') as fw:\n",
    "    pickle.dump(idx_to_item, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "\n",
    "# 업로드할 데이터 경로 설정/ 없는 경로로 설정해주면 새로 생성해줌\n",
    "upload_project_id = \"level3-416207\" \n",
    "upload_dataset_id = 'l3_30'\n",
    "upload_table_id = 'upload_test'\n",
    "\n",
    "# 업로드\n",
    "#pandas_gbq.to_gbq(df, destination_table=f'{upload_dataset_id}.{upload_table_id}', project_id=upload_project_id, if_exists='replace', credentials=credentials)\n",
    "\n",
    "# '''\n",
    "# if_exists 매개변수\n",
    "# 'fail': 기존 테이블이 이미 존재하는 경우에는 업로드를 실패시킵니다. 기본값은 'fail'입니다.\n",
    "# 'replace': 기존 테이블이 이미 존재하는 경우에는 해당 테이블을 덮어씁니다.\n",
    "# 'append': 기존 테이블이 이미 존재하는 경우에는 데이터를 테이블에 추가합니다.\n",
    "# ''' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
