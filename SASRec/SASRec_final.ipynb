{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib3gvT2ilbxm"
      },
      "source": [
        "## Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DImYt6t4lbxm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL0hmlgelbxm"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDx1oOIDlbxm"
      },
      "outputs": [],
      "source": [
        "# model setting\n",
        "max_len = 10\n",
        "hidden_units = 50\n",
        "num_heads = 1\n",
        "num_layers = 2\n",
        "dropout_rate=0.5\n",
        "num_workers = 1\n",
        "device = 'cuda' # gpu 환경 확인 필요\n",
        "\n",
        "# training setting\n",
        "lr = 0.001\n",
        "batch_size = 128\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joV1Znhclbxm"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT_FILE = \"../Data/config/level3-416207-893f91c9529e.json\"  # 키 json 파일\n",
        "\n",
        "# Credentials 객체 생성\n",
        "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n",
        "\n",
        "# 빅쿼리 클라이언트 객체 생성\n",
        "project_id = \"level3-416207\"\n",
        "client = bigquery.Client(credentials=credentials, project=project_id)\n",
        "\n",
        "# 쿼리 실행\n",
        "# 빅쿼리 디렉토리는 <프로젝트ID>.<데이터셋ID>.<테이블ID> 순으로 저장되어있음 ex) level3-416207.l3_30.l3_30\n",
        "QUERY = (\n",
        "    '''\n",
        "    SELECT *\n",
        "    FROM `level3-416207.log_129.ip_time_url_sorted_by_ip_time`\n",
        "    ''')\n",
        "\n",
        "\n",
        "# API request\n",
        "df = client.query(QUERY).to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../Data/data10.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[['hashed_ip', 'local_time', 'request_url_endpoint']]\n",
        "df['local_time'] = pd.to_datetime(df['local_time'], format='%d/%b/%Y:%H:%M:%S')\n",
        "df['timestamp']=pd.to_datetime(df['local_time']).astype(int)//10**9\n",
        "df = df[['hashed_ip', 'request_url_endpoint', 'timestamp']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "spec = df[df['request_url_endpoint'].str.startswith('/spec')]\n",
        "comment = df[df['request_url_endpoint'].str.startswith('/comments')]\n",
        "product = df[df['request_url_endpoint'].str.startswith('/products')]\n",
        "\n",
        "df = pd.concat([spec, comment, product])\n",
        "\n",
        "df = df.sort_values(['hashed_ip', 'timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['product_id'] = df['request_url_endpoint'].str.split('/').str[2]\n",
        "df = df[df['product_id'].apply(lambda x: len(str(x)) == len('db696dbc255f0443bb7f782ac0ec24d45003f792cb9dbb7c810f7dd8216a18b2'))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_432140/1019417155.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['user']=df['hashed_ip']\n",
            "/tmp/ipykernel_432140/1019417155.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['item']=df['product_id']\n",
            "/tmp/ipykernel_432140/1019417155.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['time']=df['timestamp']\n"
          ]
        }
      ],
      "source": [
        "df['user']=df['hashed_ip']\n",
        "df['item']=df['product_id']\n",
        "df['time']=df['timestamp']\n",
        "\n",
        "del df['hashed_ip'], df['request_url_endpoint'], df['timestamp'], df['product_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>706186</th>\n",
              "      <td>00012dd418cdd7e02ff8b1a54f0a8d69</td>\n",
              "      <td>1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...</td>\n",
              "      <td>1707313910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706185</th>\n",
              "      <td>00012dd418cdd7e02ff8b1a54f0a8d69</td>\n",
              "      <td>1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...</td>\n",
              "      <td>1707313910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706184</th>\n",
              "      <td>00012dd418cdd7e02ff8b1a54f0a8d69</td>\n",
              "      <td>1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...</td>\n",
              "      <td>1707313910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706221</th>\n",
              "      <td>00012dd418cdd7e02ff8b1a54f0a8d69</td>\n",
              "      <td>1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...</td>\n",
              "      <td>1707313924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>706220</th>\n",
              "      <td>00012dd418cdd7e02ff8b1a54f0a8d69</td>\n",
              "      <td>1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...</td>\n",
              "      <td>1707313924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457909</th>\n",
              "      <td>fffb34b31a2814dc4554a77152e25aea</td>\n",
              "      <td>52d59acecc064fd5cf4f2e06d33369f3ac12899490fc8d...</td>\n",
              "      <td>1707496496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457908</th>\n",
              "      <td>fffb34b31a2814dc4554a77152e25aea</td>\n",
              "      <td>52d59acecc064fd5cf4f2e06d33369f3ac12899490fc8d...</td>\n",
              "      <td>1707496496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887353</th>\n",
              "      <td>fffceead2e9e91aaa68a7daec9864628</td>\n",
              "      <td>d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...</td>\n",
              "      <td>1707228606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887376</th>\n",
              "      <td>fffceead2e9e91aaa68a7daec9864628</td>\n",
              "      <td>d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...</td>\n",
              "      <td>1707228607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887375</th>\n",
              "      <td>fffceead2e9e91aaa68a7daec9864628</td>\n",
              "      <td>d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...</td>\n",
              "      <td>1707228607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226502 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    user  \\\n",
              "706186  00012dd418cdd7e02ff8b1a54f0a8d69   \n",
              "706185  00012dd418cdd7e02ff8b1a54f0a8d69   \n",
              "706184  00012dd418cdd7e02ff8b1a54f0a8d69   \n",
              "706221  00012dd418cdd7e02ff8b1a54f0a8d69   \n",
              "706220  00012dd418cdd7e02ff8b1a54f0a8d69   \n",
              "...                                  ...   \n",
              "457909  fffb34b31a2814dc4554a77152e25aea   \n",
              "457908  fffb34b31a2814dc4554a77152e25aea   \n",
              "887353  fffceead2e9e91aaa68a7daec9864628   \n",
              "887376  fffceead2e9e91aaa68a7daec9864628   \n",
              "887375  fffceead2e9e91aaa68a7daec9864628   \n",
              "\n",
              "                                                     item        time  \n",
              "706186  1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...  1707313910  \n",
              "706185  1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...  1707313910  \n",
              "706184  1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...  1707313910  \n",
              "706221  1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...  1707313924  \n",
              "706220  1ca8539c8825d356c4143f9a5c8b3e3b3f7b25cbdcbe0c...  1707313924  \n",
              "...                                                   ...         ...  \n",
              "457909  52d59acecc064fd5cf4f2e06d33369f3ac12899490fc8d...  1707496496  \n",
              "457908  52d59acecc064fd5cf4f2e06d33369f3ac12899490fc8d...  1707496496  \n",
              "887353  d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...  1707228606  \n",
              "887376  d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...  1707228607  \n",
              "887375  d25b34ce2212e08ba68f9082940856ff7a3a9b5de7b9cd...  1707228607  \n",
              "\n",
              "[226502 rows x 3 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# user별 interaction 개수를 계산\n",
        "user_interaction_counts = df['user'].value_counts()\n",
        "\n",
        "# interaction이 3개 이상인 user의 목록을 가져옴\n",
        "selected_users = user_interaction_counts[user_interaction_counts >= 3].index\n",
        "\n",
        "# interaction이 3개 이상인 user에 대한 데이터만 남김\n",
        "df = df[df['user'].isin(selected_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ2YmI3llbxn",
        "outputId": "75e3c02c-1903-404d-8f44-f66a2c5d3aea"
      },
      "outputs": [],
      "source": [
        "item_ids = df['item'].unique()\n",
        "user_ids = df['user'].unique()\n",
        "num_item, num_user = len(item_ids), len(user_ids)\n",
        "num_batch = num_user // batch_size\n",
        "\n",
        "# user, item indexing\n",
        "item2idx = pd.Series(data=np.arange(len(item_ids))+1, index=item_ids) # item re-indexing (1~num_item)\n",
        "user2idx = pd.Series(data=np.arange(len(user_ids)), index=user_ids) # user re-indexing (0~num_user-1)\n",
        "\n",
        "# dataframe indexing\n",
        "df = pd.merge(df, pd.DataFrame({'item': item_ids, 'item_idx': item2idx[item_ids].values}), on='item', how='inner')\n",
        "df = pd.merge(df, pd.DataFrame({'user': user_ids, 'user_idx': user2idx[user_ids].values}), on='user', how='inner')\n",
        "df.sort_values(['user_idx', 'time'], inplace=True)\n",
        "del df['item'], df['user']\n",
        "\n",
        "# train set, valid set 생성\n",
        "users = defaultdict(list) # defaultdict은 dictionary의 key가 없을때 default 값을 value로 반환\n",
        "user_train = {}\n",
        "user_valid = {}\n",
        "for u, i, t in zip(df['user_idx'], df['item_idx'], df['time']):\n",
        "    users[u].append(i)\n",
        "\n",
        "for user in users:\n",
        "    user_train[user] = users[user][:-1]\n",
        "    user_valid[user] = [users[user][-1]]\n",
        "\n",
        "print(f'num users: {num_user}, num items: {num_item}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crj9yVT5lbxn"
      },
      "outputs": [],
      "source": [
        "# for training, data sampling\n",
        "def random_neg(l, r, s):\n",
        "    # log에 존재하는 아이템과 겹치지 않도록 sampling\n",
        "    t = np.random.randint(l, r)\n",
        "    while t in s:\n",
        "        t = np.random.randint(l, r)\n",
        "    return t\n",
        "\n",
        "def sample_batch(user_train, num_user, num_item, batch_size, max_len):\n",
        "    def sample():\n",
        "\n",
        "        user = np.random.randint(num_user)  # user를 임의로 선택\n",
        "\n",
        "        # 미리 max_len에 해당하는 array 생성, zero padding\n",
        "        seq = np.zeros([max_len], dtype=np.int32)\n",
        "        pos = np.zeros([max_len], dtype=np.int32)\n",
        "        neg = np.zeros([max_len], dtype=np.int32)\n",
        "        nxt = user_train[user][-1]\n",
        "        idx = max_len - 1\n",
        "\n",
        "        # negative sample은 train sequence에 없는 item 사용\n",
        "        train_item = set(user_train[user])\n",
        "        for i in reversed(user_train[user][:-1]):\n",
        "            # 미리 정의된 sequence를 역순으로 채움, ex: seq = [0,0,0,1,2,3] (0은 pad)\n",
        "            seq[idx] = i\n",
        "            pos[idx] = nxt\n",
        "            if nxt != 0:\n",
        "                neg[idx] = random_neg(1, num_item + 1, train_item)\n",
        "            nxt = i\n",
        "            idx -= 1\n",
        "            if idx == -1: break\n",
        "        return (user, seq, pos, neg)\n",
        "    user, seq, pos, neg = zip(*[sample() for _ in range(batch_size)])\n",
        "    user, seq, pos, neg = np.array(user), np.array(seq), np.array(pos), np.array(neg)\n",
        "    return user, seq, pos, neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLHK0oVlbxn"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69zDNy6Albxo"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, hidden_units, dropout_rate):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.dropout = nn.Dropout(dropout_rate) # TODO1: dropout rate를 hyper parameter로 사용하여 dropout layer를 구현하세요.\n",
        "\n",
        "    def forward(self, Q, K, V, mask):\n",
        "        attn_score = torch.matmul(Q, K.transpose(2, 3)) / math.sqrt(self.hidden_units)\n",
        "        attn_score = attn_score.masked_fill(mask == 0, -1e9)  # 유사도가 0인 지점은 -infinity로 보내 softmax 결과가 0이 되도록 함\n",
        "        attn_dist = self.dropout(F.softmax(attn_score, dim=-1))  # attention distribution\n",
        "        output = torch.matmul(attn_dist, V)  # dim of output : batchSize x num_head x seqLen x hidden_units\n",
        "        return output, attn_dist\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, hidden_units, dropout_rate):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads # head의 수\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        # query, key, value, output 생성을 위해 Linear 모델 생성\n",
        "        self.W_Q = nn.Linear(hidden_units, hidden_units, bias=False)\n",
        "        self.W_K = nn.Linear(hidden_units, hidden_units, bias=False)\n",
        "        self.W_V = nn.Linear(hidden_units, hidden_units, bias=False)\n",
        "        self.W_O = nn.Linear(hidden_units, hidden_units, bias=False)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(hidden_units, dropout_rate) # TODO2: ScaledDotProductAttention class를 사용하여 attention layer를 구현하세요.\n",
        "        self.dropout = nn.Dropout(dropout_rate) # dropout rate\n",
        "        self.layerNorm = nn.LayerNorm(hidden_units, 1e-6) # layer normalization\n",
        "\n",
        "    def forward(self, enc, mask):\n",
        "        residual = enc # residual connection을 위해 residual 부분을 저장\n",
        "        batch_size, seqlen = enc.size(0), enc.size(1)\n",
        "\n",
        "        # Query, Key, Value를 (num_head)개의 Head로 나누어 각기 다른 Linear projection을 통과시킴\n",
        "        Q = self.W_Q(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units)\n",
        "        K = self.W_K(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units)\n",
        "        V = self.W_V(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units)\n",
        "\n",
        "        # Head별로 각기 다른 attention이 가능하도록 Transpose 후 각각 attention에 통과시킴\n",
        "        Q, K, V = Q.transpose(1, 2), K.transpose(1, 2), V.transpose(1, 2)\n",
        "        output, attn_dist = self.attention(Q, K, V, mask)\n",
        "\n",
        "        # 다시 Transpose한 후 모든 head들의 attention 결과를 합칩니다.\n",
        "        output = output.transpose(1, 2).contiguous()\n",
        "        output = output.view(batch_size, seqlen, -1)\n",
        "\n",
        "        # Linear Projection, Dropout, Residual sum, and Layer Normalization\n",
        "        output = self.layerNorm(self.dropout(self.W_O(output)) + residual)\n",
        "        return output, attn_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lclDm0Yolbxp"
      },
      "source": [
        "### Position-wise Feed Forward Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYp3RAIllbxp"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, hidden_units, dropout_rate):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "\n",
        "        self.W_1 = nn.Linear(hidden_units, hidden_units)\n",
        "        self.W_2 = nn.Linear(hidden_units, hidden_units)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layerNorm = nn.LayerNorm(hidden_units, 1e-6) # layer normalization\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        output = self.W_2(F.relu(self.dropout(self.W_1(x))))\n",
        "        output = self.layerNorm(self.dropout(output) + residual)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUJ68SZglbxp"
      },
      "outputs": [],
      "source": [
        "class SASRecBlock(nn.Module):\n",
        "    def __init__(self, num_heads, hidden_units, dropout_rate):\n",
        "        super(SASRecBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads, hidden_units, dropout_rate)\n",
        "        self.pointwise_feedforward = PositionwiseFeedForward(hidden_units, dropout_rate)\n",
        "\n",
        "    def forward(self, input_enc, mask):\n",
        "        output_enc, attn_dist = self.attention(input_enc, mask)\n",
        "        output_enc = self.pointwise_feedforward(output_enc)\n",
        "        return output_enc, attn_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfIEkU3Elbxp"
      },
      "source": [
        "### SASRec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTC2LUAglbxp"
      },
      "outputs": [],
      "source": [
        "class SASRec(nn.Module):\n",
        "    def __init__(self, num_user, num_item, hidden_units, num_heads, num_layers, maxlen, dropout_rate, device):\n",
        "        super(SASRec, self).__init__()\n",
        "\n",
        "        self.num_user = num_user\n",
        "        self.num_item = num_item\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.item_emb = nn.Embedding(num_item + 1, hidden_units, padding_idx=0) # TODO3: item embedding을 생성하세요. (padding index 고려 필요)\n",
        "        self.pos_emb = nn.Embedding(maxlen, hidden_units) # learnable positional encoding\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.emb_layernorm = nn.LayerNorm(hidden_units, eps=1e-6)\n",
        "\n",
        "        self.blocks = nn.ModuleList([SASRecBlock(num_heads, hidden_units, dropout_rate) for _ in range(num_layers)])\n",
        "\n",
        "    def feats(self, log_seqs):\n",
        "        seqs = self.item_emb(torch.LongTensor(log_seqs).to(self.device))\n",
        "        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1])\n",
        "        seqs += self.pos_emb(torch.LongTensor(positions).to(self.device))\n",
        "        seqs = self.emb_layernorm(self.dropout(seqs))\n",
        "\n",
        "        # masking\n",
        "        mask_pad = torch.BoolTensor(log_seqs > 0).unsqueeze(1).unsqueeze(1) # TODO4: log_seqs=0인 경우 masking이 필요합니다. 해당 조건을 만족하는 mask를 구현하세요.\n",
        "        # 참고 unsqueeze operation을 통해 mask_pad와 mask_time의 차원을 맞춰주는 과정이 필요합니다.\n",
        "        mask_time = (1 - torch.triu(torch.ones((1, 1, seqs.size(1), seqs.size(1))), diagonal=1)).bool() # sequence의 순서를 고려\n",
        "        mask = (mask_pad & mask_time).to(self.device)\n",
        "        for block in self.blocks:\n",
        "            seqs, attn_dist = block(seqs, mask)\n",
        "        return seqs\n",
        "\n",
        "    def forward(self, log_seqs, pos_seqs, neg_seqs):\n",
        "        # 학습에 사용\n",
        "        feats = self.feats(log_seqs) # TODO5: Transformer를 사용해서 token 별 연산을 수행하세요.\n",
        "        pos_embs = self.item_emb(torch.LongTensor(pos_seqs).to(self.device))\n",
        "        neg_embs = self.item_emb(torch.LongTensor(neg_seqs).to(self.device))\n",
        "\n",
        "        pos_logits = (feats * pos_embs).sum(dim=-1)\n",
        "        neg_logits = (feats * neg_embs).sum(dim=-1)\n",
        "        return pos_logits, neg_logits\n",
        "\n",
        "    def predict(self, log_seqs, item_indices):\n",
        "        # evaluation에 사용\n",
        "        final_feats = self.feats(log_seqs)[:, -1, :]\n",
        "        item_embs = self.item_emb(torch.LongTensor(item_indices).to(self.device))\n",
        "        logits = item_embs.matmul(final_feats.unsqueeze(-1)).squeeze(-1)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi23gs2Klbxp"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X8abJF4lbxp"
      },
      "outputs": [],
      "source": [
        "# setting\n",
        "model = SASRec(num_user, num_item, hidden_units, num_heads, num_layers, max_len, dropout_rate, device)\n",
        "model.to(device)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj2VxBPQlbxp",
        "outputId": "95f6e67f-4eb2-483e-8ab8-ba9553c89ac8"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    tbar = tqdm(range(num_batch))\n",
        "    for step in tbar: # num_batch만큼 sampling\n",
        "        user, seq, pos, neg = sample_batch(user_train, num_user, num_item, batch_size, max_len)\n",
        "        pos_logits, neg_logits = model(seq, pos, neg)\n",
        "        pos_labels, neg_labels = torch.ones(pos_logits.shape, device=device), torch.zeros(neg_logits.shape, device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        indices = np.where(pos != 0)\n",
        "        loss = criterion(pos_logits[indices], pos_labels[indices])\n",
        "        loss += criterion(neg_logits[indices], neg_labels[indices])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tbar.set_description(f'Epoch: {epoch:3d}| Step: {step:3d}| Train loss: {loss:.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Nf2KXclbxp"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sks4zbN_lbxp"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "NDCG = 0.0 # NDCG@10\n",
        "HIT = 0.0 # HIT@10\n",
        "\n",
        "num_item_sample = 18580\n",
        "num_user_sample = 1000\n",
        "users = np.random.randint(0, num_user, num_user_sample) # 1000개만 sampling 하여 evaluation\n",
        "for u in users:\n",
        "    seq = user_train[u][-max_len:]\n",
        "    rated = set(user_train[u] + user_valid[u])\n",
        "    item_idx = user_valid[u] + [random_neg(1, num_item + 1, rated) for _ in range(num_item_sample)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = -model.predict(np.array([seq]), np.array(item_idx))\n",
        "        predictions = predictions[0]\n",
        "        rank = predictions.argsort().argsort()[0].item()\n",
        "\n",
        "    if rank < 10: # 만약 예측 성공시\n",
        "        NDCG += 1 / np.log2(rank + 2)\n",
        "        HIT += 1\n",
        "print(f'NDCG@10: {NDCG/num_user_sample}| HIT@10: {HIT/num_user_sample}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
